---
permalink: /
title: ""
excerpt: ""
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---

{% if site.google_scholar_stats_use_cdn %}
{% assign gsDataBaseUrl = "https://cdn.jsdelivr.net/gh/" | append: site.repository | append: "@" %}
{% else %}
{% assign gsDataBaseUrl = "https://raw.githubusercontent.com/" | append: site.repository | append: "/" %}
{% endif %}
{% assign url = gsDataBaseUrl | append: "google-scholar-stats/gs_data_shieldsio.json" %}

<span class='anchor' id='about-me'></span>

# ğŸ‘¨â€ğŸ’» About Me
I am now a third-year PhD student at Beijing Jiaotong University, advised by Prof. Yufeng Chen, Prof. Kaiyu Huang, and Prof. Jinan Xu. Before that, I started my master's degree in 2021 and transferred to the doctoral program in 2023. I am now interning at WeChat AI, Tencent.

My research interests include **Multilingual large language models**; **Multilingual analysis and interpretability**; **Knowledge transfer and distillation**.


# ğŸ”¥ News
- *2025.10*: [M-Thinker](https://arxiv.org/abs/2510.07300) has been released on arxiv. Code, data, and models are available at [https://github.com/XZhang00/M-Thinker](https://github.com/XZhang00/M-Thinker).
- *2025.09*: &nbsp;ğŸ‰ğŸ‰ [CM-Align](https://arxiv.org/abs/2509.08541) has been accepted by EMNLP 2025 (findings)!
- *2025.05*: &nbsp;ğŸ‰ğŸ‰ Two papers ([LayerMoE](https://arxiv.org/abs/2505.22582) and [AlignDistil](https://arxiv.org/abs/2503.02832)) have been accepted by ACL 2025! See you in Vienna. 
- *2025.03*: [DSKDv2](https://arxiv.org/abs/2504.11426) has been released on arxiv.
- *2024.12*: &nbsp;ğŸ‰ğŸ‰ [LU-LAFNs](https://arxiv.org/abs/2406.16416) has been accepted by COLING 2025! 
- *2024.09*: &nbsp;ğŸ‰ğŸ‰ [DSKD](https://arxiv.org/abs/2406.17328) has been accepted by EMNLP 2024! 

# ğŸ“ Selected Papers [[Full]](https://scholar.google.com.hk/citations?user=rh-QHwQAAAAJ&hl=zh-CN)

<!-- <div class='paper-box'><div class='paper-box-image'><div><div class="badge">CVPR 2016</div><img src='images/500x300.png' alt="sym" width="100%"></div></div> -->
<!-- <div class='paper-box-text' markdown="1"> -->
## Preprint
- [Think Natively: Unlocking Multilingual Reasoning with Consistency-Enhanced Reinforcement Learning](https://arxiv.org/abs/2510.07300)

  **Xue Zhang**, Yunlong Liang, Fandong Meng, Songming Zhang, Kaiyu Huang, Yufeng Chen, Jinan Xu, Jie Zhou

- [A Dual-Space Framework for General Knowledge Distillation of Large Language Models](https://arxiv.org/abs/2504.11426)

  **Xue Zhang\***, Songming Zhang*, Yunlong Liang, Fandong Meng, Yufeng Chen, Jinan Xu, Jie Zhou

  ---

## Publications
- [CM-Align: Consistency-based Multilingual Alignment for Large Language Models](https://arxiv.org/abs/2509.08541) (**EMNLP 2025 Findings**)

  **Xue Zhang**, Yunlong Liang, Fandong Meng, Songming Zhang, Yufeng Chen, Jinan Xu, Jie Zhou

- [Less, but Better: Efficient Multilingual Expansion for LLMs via Layer-wise Mixture-of-Experts](https://arxiv.org/abs/2505.22582) (**ACL 2025**)

  **Xue Zhang**, Yunlong Liang, Fandong Meng, Songming Zhang, Yufeng Chen, Jinan Xu, Jie Zhou

- [Multilingual Knowledge Editing with Language-Agnostic Factual Neurons](https://arxiv.org/abs/2406.16416) (**COLING 2025**)

  **Xue Zhang**, Yunlong Liang, Fandong Meng, Songming Zhang, Yufeng Chen, Jinan Xu, Jie Zhou

- [AlignDistil: Token-Level Language Model Alignment as Adaptive Policy Distillation](https://arxiv.org/abs/2503.02832) (**ACL 2025**)

  Songming Zhang, **Xue Zhang**, Tong Zhang, Bojie Hu, Yufeng Chen, Jinan Xu

- [Dual-Space Knowledge Distillation for Large Language Models](https://arxiv.org/abs/2406.17328) (**EMNLP 2024**)

  Songming Zhang, **Xue Zhang**, Zengkui Sun, Yufeng Chen, Jinan Xu

- [A Quality-based Syntactic Template Retriever for Syntactically-controlled Paraphrase Generation](https://arxiv.org/abs/2310.13262) (**EMNLP 2023**)

  **Xue Zhang**, Songming Zhang, Yunlong Liang, Yufeng Chen, Jian Liu, Wenjuan Han, Jinan Xu


<!-- [**Project**](https://scholar.google.com/citations?view_op=view_citation&hl=zh-CN&user=DhtAFkwAAAAJ&citation_for_view=DhtAFkwAAAAJ:ALROH1vI_8AC) <strong><span class='show_paper_citations' data='DhtAFkwAAAAJ:ALROH1vI_8AC'></span></strong>
- Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet. 
</div>
</div> -->

<!-- - [Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet](https://github.com), A, B, C, **CVPR 2020** -->


# ğŸ“– Educations
- *2023.09 - Now*, Beijing Jiaotong University, PhD Student. 
- *2021.09 - 2023.06*, Beijing Jiaotong University, Master.
- *2017.09 - 2021.06*, Northeastern University at Qinhuangdao, Bachelor. 


# ğŸ’» Internships
- *2024.01 - Now*, WeChat, Tencent.
- *2022.02 - 2023.09*, TI Cloud Inc.

# ğŸ”– Services
- Workshop Student Chair: As one of the student chairs, I will organize a workshop ("Multilinguality in the Era of Large Language Models") at the ACL 2026 conference.
- ACL ARR 2023-2025, Reviewer
- IEEE TAMC, Reviewer

