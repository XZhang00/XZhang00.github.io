---
permalink: /
title: ""
excerpt: ""
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---

{% if site.google_scholar_stats_use_cdn %}
{% assign gsDataBaseUrl = "https://cdn.jsdelivr.net/gh/" | append: site.repository | append: "@" %}
{% else %}
{% assign gsDataBaseUrl = "https://raw.githubusercontent.com/" | append: site.repository | append: "/" %}
{% endif %}
{% assign url = gsDataBaseUrl | append: "google-scholar-stats/gs_data_shieldsio.json" %}

<span class='anchor' id='about-me'></span>

# 👨‍💻 About Me
I am now a third-year PhD student at Beijing Jiaotong University, advised by Prof. Yufeng Chen, Prof. Kaiyu Huang, and Prof. Jinan Xu. Before that, I started my master's degree in 2021 and transferred to the doctoral program in 2023. I am now interning at WeChat AI, Tencent.

My research interests include **Multilingual large language models**; **Multilingual analysis and interpretability**; **Knowledge transfer and distillation**.


# 🔥 News
- *2025.10*: [M-Thinker](https://arxiv.org/abs/2510.07300) has been released on arxiv. Code, data, and models are available at [https://github.com/XZhang00/M-Thinker](https://github.com/XZhang00/M-Thinker).
- *2025.09*: &nbsp;🎉🎉 CM-Align has been accepted by EMNLP 2025 (findings)!
- *2025.05*: &nbsp;🎉🎉 Two papers have been accepted by ACL 2025! See you in Vienna. 
- *2025.03*: [DSKDv2](https://arxiv.org/abs/2504.11426) has been released on arxiv.
- *2024.12*: &nbsp;🎉🎉 [LU-LAFNs](https://arxiv.org/abs/2406.16416) has been accepted by COLING 2025! 
- *2024.09*: &nbsp;🎉🎉 [DSKD](https://arxiv.org/abs/2406.17328) has been accepted by EMNLP 2024! 

# 📝 Selected Papers [[Full]](https://scholar.google.com/citations?user=u_bYOuYAAAAJ&hl=zh-CN)

<!-- <div class='paper-box'><div class='paper-box-image'><div><div class="badge">CVPR 2016</div><img src='images/500x300.png' alt="sym" width="100%"></div></div> -->
<!-- <div class='paper-box-text' markdown="1"> -->
## Preprint

- [A Dual-Space Framework for General Knowledge Distillation of Large Language Models](https://arxiv.org/abs/2504.11426)

  Xue Zhang*, **Songming Zhang\***, Yunlong Liang, Fandong Meng, Yufeng Chen, Jinan Xu, Jie Zhou

  ---

## Publications

- [AlignDistil: Token-Level Language Model Alignment as Adaptive Policy Distillation](https://arxiv.org/abs/2503.02832) (**ACL 2025 Main**)

  **Songming Zhang**, Xue Zhang, Tong Zhang, Bojie Hu, Yufeng Chen, Jinan Xu

- [Dual-Space Knowledge Distillation for Large Language Models](https://arxiv.org/abs/2406.17328) (**EMNLP 2024 Main**)

  **Songming Zhang**, Xue Zhang, Zengkui Sun, Yufeng Chen, Jinan Xu

- [Towards Understanding and Improving Knowledge Distillation
for Neural Machine Translation](https://arxiv.org/abs/2305.08096) (**ACL 2023 Main**)

  **Songming Zhang**, Yunlong Liang, Shuaibo Wang, Yufeng Chen, Wenjuan Han, Jian Liu, Jinan Xu

- [Conditional Bilingual Mutual Information Based Adaptive Training for Neural Machine Translation](https://arxiv.org/abs/2203.02951) (**ACL 2022 Main**)

  **Songming Zhang\***, Yijin Liu*, Fandong Meng, Yufeng Chen, Jinan Xu, Jian Liu, Jie Zhou


<!-- [**Project**](https://scholar.google.com/citations?view_op=view_citation&hl=zh-CN&user=DhtAFkwAAAAJ&citation_for_view=DhtAFkwAAAAJ:ALROH1vI_8AC) <strong><span class='show_paper_citations' data='DhtAFkwAAAAJ:ALROH1vI_8AC'></span></strong>
- Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet. 
</div>
</div> -->

<!-- - [Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet](https://github.com), A, B, C, **CVPR 2020** -->


# 📖 Educations
- *2022.09 - Now*, Beijing Jiaotong University, PhD Student. 
- *2020.09 - 2022.06*, Beijing Jiaotong University, Master.
- *2016.09 - 2020.06*, Beijing University of Chemical Technology, Bachelor. 

<!-- # 💬 Invited Talks
- *2021.06*, Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet. 
- *2021.03*, Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet.  \| [\[video\]](https://github.com/) -->

# 💻 Internships
- *2024.07 - Now*, WeChat, Tencent.
- *2022.02 - 2024.03*, TI Cloud Inc.
- *2021.01 - 2022.01*, WeChat AI, Tencent.

# 🔖 Services
- ACL 2023, Reviewer
- ACL ARR 2023-2025, Reviewer

# 🎖 Honors and Awards
- *2025*, National Scholarship. 
